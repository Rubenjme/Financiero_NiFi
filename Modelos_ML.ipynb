{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelos para detección de transacciones financieras fraudulentas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Descripción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se entrenan y evalúan varios modelos de Machine Learning (Logistic Regression, Random Forest y XGBoost) para la detección de transacciones fraudulentas en tarjetas de crédito. El objetivo es comparar distintas técnicas de clasificación y escoger la mejor en términos de recall, precision y otras métricas adecuadas para un problema altamente desbalanceado.  \n",
    "\n",
    "Los apartados tratados son:\n",
    "- Carga del dataset tras un EDA previo.\n",
    "- División en entrenamiento y test (estratificado).\n",
    "- Entrenamiento de varios algoritmos.\n",
    "- Evaluación con métricas (matriz de confusión, AUPRC, etc.).\n",
    "- Comparación de los resultados.\n",
    "- Conclusiones finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Módulos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    precision_recall_curve, auc, roc_auc_score\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cargo dataset tras EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset: (283726, 31)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard_clean.csv\") \n",
    "print(\"Tamaño del dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preparación de features y target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class'])  # El resto de columnas son predictoras\n",
    "y = df['class']                 # Clase (0: No Fraude, 1: Fraude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **División en entrenamiento y test (estratificado por estar desbalanceado)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de clases en entrenamiento:\n",
      "class\n",
      "0    0.998332\n",
      "1    0.001668\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución de clases en test:\n",
      "class\n",
      "0    0.998336\n",
      "1    0.001664\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=7\n",
    ")\n",
    "\n",
    "print(\"\\nDistribución de clases en entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nDistribución de clases en test:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Función para evaluar los modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(model, X_test, y_test, umbral=0.5):\n",
    "    \"\"\"\n",
    "    Imprime matriz de confusión, metrics, AUPRC, ROC-AUC, etc.\n",
    "    umbral es el corte para predecir 0 o 1 a partir de la probabilidad\n",
    "    \"\"\"\n",
    "    \n",
    "    y_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades de la clase positiva (fraude=1)\n",
    "    y_pred = (y_proba >= umbral).astype(int)     # Predicciones binarias, según umbral\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)        # Matriz de confusión\n",
    "    \n",
    "    # Precision, Recall, AUPRC\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_proba)     # ROC AUC\n",
    "    \n",
    "    # Clasification Report\n",
    "    clf_report = classification_report(y_test, y_pred, digits=4)\n",
    "    \n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(cm)\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(clf_report)\n",
    "    print(f\"AUPRC = {pr_auc:.4f}\")\n",
    "    print(f\"ROC-AUC = {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entrenamiento de los modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regresión logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "     MODELO 1: LOGISTIC REGRESSION\n",
      "============================================\n",
      "Matriz de Confusión:\n",
      "[[70801    13]\n",
      " [   35    83]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9995    0.9998    0.9997     70814\n",
      "           1     0.8646    0.7034    0.7757       118\n",
      "\n",
      "    accuracy                         0.9993     70932\n",
      "   macro avg     0.9320    0.8516    0.8877     70932\n",
      "weighted avg     0.9993    0.9993    0.9993     70932\n",
      "\n",
      "AUPRC = 0.7358\n",
      "ROC-AUC = 0.9825\n"
     ]
    }
   ],
   "source": [
    "print(\"============================================\")\n",
    "print(\"     MODELO 1: LOGISTIC REGRESSION\")\n",
    "print(\"============================================\")\n",
    "lr = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    max_iter=10000,\n",
    "    random_state=7\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "evaluar_modelo(lr, X_test, y_test, umbral=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "     MODELO 2: RANDOM FOREST\n",
      "============================================\n",
      "Mejores parámetros: {'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "Mejor puntuación (average_precision): 0.8243824897511809\n",
      "Matriz de Confusión:\n",
      "[[70802    12]\n",
      " [   23    95]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9998    0.9998     70814\n",
      "           1     0.8879    0.8051    0.8444       118\n",
      "\n",
      "    accuracy                         0.9995     70932\n",
      "   macro avg     0.9438    0.9025    0.9221     70932\n",
      "weighted avg     0.9995    0.9995    0.9995     70932\n",
      "\n",
      "AUPRC = 0.8443\n",
      "ROC-AUC = 0.9432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "print(\"\\n============================================\")\n",
    "print(\"     MODELO 2: RANDOM FOREST\")\n",
    "print(\"============================================\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 100],\n",
    "    'max_depth': [None],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=7)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='average_precision',  # métrica para datos desbalanceados\n",
    "    cv=3,                         # 3-fold cross-validation\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación (average_precision):\", grid_search.best_score_)\n",
    "\n",
    "# Entreno un RandomForest con los mejores parámetros\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "evaluar_modelo(best_rf, X_test, y_test, umbral=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost (XGBClassifier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "     MODELO 3: XGBOOST CLASSIFIER\n",
      "============================================\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Mejores parámetros (XGB): {'subsample': 1.0, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
      "Mejor puntuación (avg_precision): 0.8398824278001081\n",
      "Matriz de Confusión:\n",
      "[[70801    13]\n",
      " [   25    93]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9996    0.9998    0.9997     70814\n",
      "           1     0.8774    0.7881    0.8304       118\n",
      "\n",
      "    accuracy                         0.9995     70932\n",
      "   macro avg     0.9385    0.8940    0.9150     70932\n",
      "weighted avg     0.9994    0.9995    0.9994     70932\n",
      "\n",
      "AUPRC = 0.8250\n",
      "ROC-AUC = 0.9854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print(\"\\n============================================\")\n",
    "print(\"     MODELO 3: XGBOOST CLASSIFIER\")\n",
    "print(\"============================================\")\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [25, 50, 100],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_clf = XGBClassifier(random_state=7, eval_metric='logloss')\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_clf,\n",
    "    param_distributions=param_dist,\n",
    "    scoring='average_precision',\n",
    "    n_iter=5,      # número de combinaciones que testeará\n",
    "    cv=3,          # cross-validation\n",
    "    verbose=1,\n",
    "    random_state=7,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros (XGB):\", random_search.best_params_)\n",
    "print(\"Mejor puntuación (avg_precision):\", random_search.best_score_)\n",
    "\n",
    "best_xgb = random_search.best_estimator_\n",
    "evaluar_modelo(best_xgb, X_test, y_test, umbral=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Comparación de resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "     COMPARACIÓN DE MODELOS (AUPRC/ROC-AUC)\n",
      "============================================\n",
      "LogisticReg -> AUPRC: 0.7358 | ROC-AUC: 0.9825\n",
      "RandomForest -> AUPRC: 0.8443 | ROC-AUC: 0.9432\n",
      "XGBoost -> AUPRC: 0.8250 | ROC-AUC: 0.9854\n"
     ]
    }
   ],
   "source": [
    "models = [('LogisticReg', lr), ('RandomForest', best_rf), ('XGBoost', best_xgb)]\n",
    "metricas = []\n",
    "\n",
    "for name, model in models:\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    metricas.append((name, pr_auc, roc_auc))\n",
    "\n",
    "print(\"\\n============================================\")\n",
    "print(\"     COMPARACIÓN DE MODELOS (AUPRC/ROC-AUC)\")\n",
    "print(\"============================================\")\n",
    "for m in metricas:\n",
    "    print(f\"{m[0]} -> AUPRC: {m[1]:.4f} | ROC-AUC: {m[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusiones finales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Regresión logística**  \n",
    "  De 118 fraudes en test, detecta 83 (recall=70.3%), dejando 35 sin detectar (falsos negativos).  \n",
    "  Cada vez que predice fraude, acierta un 86.5% (precision=86.5%).  \n",
    "  El AUPRC de ~0.74 indica un desempeño decente en la curva de Precisión-Recall, y su ROC-AUC ~0.98 aunque en problemas desbalanceados como este, el AUPRC y el recall de la clase minoritaria son más relevantes. \n",
    "\n",
    "- **Random Forest**  \n",
    "  Detecta 95 de los 118 fraudes (recall=80.5%), dejando 23 sin detectar.  \n",
    "  La precisión es ~88.8%, es decir, de los que clasifica como fraude, casi 9 de cada 10 son realmente fraudes.  \n",
    "  El AUPRC ~0.84 es muy bueno en un problema tan desbalanceado. Random Forest maneja bien la clase minoritaria.  \n",
    "  Su ROC-AUC es 0.94 (ligeramente menor que en Regresión y XGBoost), pero en fraude a menudo importa más la AUPRC y la recall de la clase 1.  \n",
    "\n",
    "- **XGBoost**  \n",
    "  Detecta 93 de los 118 fraudes (recall=78.8%), dejando 25 sin detectar.  \n",
    "  La precisión es ~87.7%, ligeramente menor que Random Forest.  \n",
    "  El AUPRC ~0.83 y el ROC-AUC ~0.98 también son muy buenos.  \n",
    "  Se queda un poco por debajo de Random Forest en recall, pero tiene una ROC-AUC más alta.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modelo          | Recall (%) | Precisión (%) | AUPRC  | ROC-AUC |\n",
    "|----------------|-----------|--------------|--------|--------|\n",
    "| Random Forest  | **80.5**  | **88.8**     | **0.8443** | 0.9432  |\n",
    "| XGBoost        | 78.8      | 87.7         | 0.8250 | **0.9854** |\n",
    "| Logistic       | 70.3      | 86.5         | 0.7358 | 0.9825  |\n",
    "\n",
    "**Mayor Recall -> Clasifico más fraudes como fraudes**   \n",
    "**Mayor Precisión -> Menos falsos positivos (Detecta como fraudes transacciones que eran buenas)**   \n",
    "**AUPRC (Área bajo la curva de Precisión-Recall) -> Muy útil en datasets desbalanceados**    \n",
    "**ROC-AUC (Área bajo la curva ROC)**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En términos de negocio, Random Forest deja menos fraudes sin detectar (23 falsos negativos), con muy pocos falsos positivos (12). XGBoost deja 25 FN, Logistic 35 FN. Por lo tanto, considerando que la prioridad es detectar el mayor número de fraudes (alto recall) con un buen balance de precisión, el modelo **Random Forest** destaca como la mejor opción entre estos tres, seguido de XGBoost en segundo lugar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
