{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelos para detección de transacciones financieras fraudulentas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Descripción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se entrenan y evalúan varios modelos de Machine Learning (Logistic Regression, Random Forest y XGBoost) para la detección de transacciones fraudulentas en tarjetas de crédito. El objetivo es comparar distintas técnicas de clasificación y escoger la mejor en términos de recall, precision y otras métricas adecuadas para un problema altamente desbalanceado.  \n",
    "\n",
    "Los apartados tratados son:\n",
    "- Carga del dataset tras un EDA previo.\n",
    "- División en entrenamiento y test (estratificado).\n",
    "- Entrenamiento de varios algoritmos.\n",
    "- Evaluación con métricas (matriz de confusión, AUPRC, etc.).\n",
    "- Comparación de los resultados.\n",
    "- Conclusiones finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Módulos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    precision_recall_curve, auc, roc_auc_score\n",
    ")\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cargo dataset tras EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset: (283726, 31)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard_clean.csv\") \n",
    "print(\"Tamaño del dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preparación de features y target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class'])  # El resto de columnas son predictoras\n",
    "y = df['class']                 # Clase (0: No Fraude, 1: Fraude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **División en entrenamiento y test (estratificado por estar desbalanceado)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de clases en entrenamiento:\n",
      "class\n",
      "0    0.998332\n",
      "1    0.001668\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución de clases en test:\n",
      "class\n",
      "0    0.998336\n",
      "1    0.001664\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=7\n",
    ")\n",
    "\n",
    "print(\"\\nDistribución de clases en entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nDistribución de clases en test:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Función para evaluar los modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(model, X_test, y_test, umbral=0.5):\n",
    "    \"\"\"\n",
    "    Imprime matriz de confusión, metrics, AUPRC, ROC-AUC, etc.\n",
    "    umbral es el corte para predecir 0 o 1 a partir de la probabilidad\n",
    "    \"\"\"\n",
    "    \n",
    "    y_proba = model.predict_proba(X_test)[:, 1]  # Probabilidades de la clase positiva (fraude=1)\n",
    "    y_pred = (y_proba >= umbral).astype(int)     # Predicciones binarias, según umbral\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)        # Matriz de confusión\n",
    "    \n",
    "    # Precision, Recall, AUPRC\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_proba)     # ROC AUC\n",
    "    \n",
    "    # Clasification Report\n",
    "    clf_report = classification_report(y_test, y_pred, digits=4)\n",
    "    \n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(cm)\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(clf_report)\n",
    "    print(f\"AUPRC = {pr_auc:.4f}\")\n",
    "    print(f\"ROC-AUC = {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entrenamiento de los modelos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regresión logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "     MODELO 1: LOGISTIC REGRESSION\n",
      "============================================\n",
      "Matriz de Confusión:\n",
      "[[70801    13]\n",
      " [   35    83]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9995    0.9998    0.9997     70814\n",
      "           1     0.8646    0.7034    0.7757       118\n",
      "\n",
      "    accuracy                         0.9993     70932\n",
      "   macro avg     0.9320    0.8516    0.8877     70932\n",
      "weighted avg     0.9993    0.9993    0.9993     70932\n",
      "\n",
      "AUPRC = 0.7358\n",
      "ROC-AUC = 0.9825\n"
     ]
    }
   ],
   "source": [
    "print(\"============================================\")\n",
    "print(\"     MODELO 1: LOGISTIC REGRESSION\")\n",
    "print(\"============================================\")\n",
    "lr = LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    max_iter=10000,\n",
    "    random_state=7\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "evaluar_modelo(lr, X_test, y_test, umbral=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "     MODELO 2: RANDOM FOREST\n",
      "============================================\n",
      "Mejores parámetros: {'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "Mejor puntuación (average_precision): 0.8243824897511809\n",
      "Matriz de Confusión:\n",
      "[[70802    12]\n",
      " [   23    95]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9998    0.9998     70814\n",
      "           1     0.8879    0.8051    0.8444       118\n",
      "\n",
      "    accuracy                         0.9995     70932\n",
      "   macro avg     0.9438    0.9025    0.9221     70932\n",
      "weighted avg     0.9995    0.9995    0.9995     70932\n",
      "\n",
      "AUPRC = 0.8443\n",
      "ROC-AUC = 0.9432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "print(\"\\n============================================\")\n",
    "print(\"     MODELO 2: RANDOM FOREST\")\n",
    "print(\"============================================\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 100],\n",
    "    'max_depth': [None],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=7)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='average_precision',  # métrica para datos desbalanceados\n",
    "    cv=3,                         # 3-fold cross-validation\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación (average_precision):\", grid_search.best_score_)\n",
    "\n",
    "# Entreno un RandomForest con los mejores parámetros\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "evaluar_modelo(best_rf, X_test, y_test, umbral=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
